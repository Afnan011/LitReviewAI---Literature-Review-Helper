{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64d020e-6583-4830-8c33-dac4a3e7c698",
   "metadata": {},
   "source": [
    "# ü§ñ LitReview AI - Advanced Literature Review Assistant\n",
    "\n",
    "> **Capstone Project for Google's 5-Day AI Agent Intensive Course**\n",
    "\n",
    "LitReview AI is a multi-agent system powered by Google's Agent Development Kit (ADK) and Gemini 2.5 Flash. It automates the process of conducting a literature review by searching for papers, selecting the most relevant ones, extracting key findings, and synthesizing a professional report with citations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b5e80-3ab2-4548-9d31-f962f3d49e96",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aab252d0-ac62-41a2-92fb-c66ae52427ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:09:43.300915Z",
     "iopub.status.busy": "2025-11-30T12:09:43.299784Z",
     "iopub.status.idle": "2025-11-30T12:09:49.500715Z",
     "shell.execute_reply": "2025-11-30T12:09:49.498855Z",
     "shell.execute_reply.started": "2025-11-30T12:09:43.300880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q google-generativeai google-adk arxiv duckduckgo-search ddgs python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b413074-34de-41fa-b9c3-765788b395b7",
   "metadata": {},
   "source": [
    "## 2. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74633ec7-1a36-493d-b00f-63205ac2ae60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:24:45.395087Z",
     "iopub.status.busy": "2025-11-30T12:24:45.394720Z",
     "iopub.status.idle": "2025-11-30T12:24:45.538110Z",
     "shell.execute_reply": "2025-11-30T12:24:45.537235Z",
     "shell.execute_reply.started": "2025-11-30T12:24:45.395064Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key loaded (length: 39)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- CRITICAL: Set API key BEFORE importing any Google libraries ---\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "except ImportError:\n",
    "    # Fallback for local testing\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    except:\n",
    "        GOOGLE_API_KEY = None\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"‚ùå GOOGLE_API_KEY not found! Please add it to Kaggle Secrets: Add-ons ‚Üí Secrets ‚Üí GOOGLE_API_KEY\")\n",
    "\n",
    "# Set as environment variable BEFORE any imports\n",
    "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
    "print(f\"‚úÖ API Key loaded (length: {len(GOOGLE_API_KEY)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e715acd9-409e-44a1-b490-8814eebfc72f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:25:07.600947Z",
     "iopub.status.busy": "2025-11-30T12:25:07.600614Z",
     "iopub.status.idle": "2025-11-30T12:25:07.607308Z",
     "shell.execute_reply": "2025-11-30T12:25:07.606281Z",
     "shell.execute_reply.started": "2025-11-30T12:25:07.600923Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import arxiv\n",
    "from duckduckgo_search import DDGS\n",
    "from google.adk.agents import LlmAgent, SequentialAgent, LoopAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.genai import types\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e21dc29-a390-4d65-b68a-84a70395a8de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:26:17.055607Z",
     "iopub.status.busy": "2025-11-30T12:26:17.054871Z",
     "iopub.status.idle": "2025-11-30T12:26:17.060916Z",
     "shell.execute_reply": "2025-11-30T12:26:17.059906Z",
     "shell.execute_reply.started": "2025-11-30T12:26:17.055577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configure Retry Options\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,\n",
    "    exp_base=7,\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "model = Gemini(model_name=MODEL_NAME, api_key=GOOGLE_API_KEY)\n",
    "GENERATION_CONFIG = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922d408-d930-41b1-a427-cf3a86867e07",
   "metadata": {},
   "source": [
    "## 3. Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd61041f-0a74-4fe3-b6f1-ef462452320e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:10:30.024232Z",
     "iopub.status.busy": "2025-11-30T12:10:30.023888Z",
     "iopub.status.idle": "2025-11-30T12:10:30.035180Z",
     "shell.execute_reply": "2025-11-30T12:10:30.033695Z",
     "shell.execute_reply.started": "2025-11-30T12:10:30.024208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def search_papers_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches for research papers on ArXiv and Web.\n",
    "    Args:\n",
    "        query: The research topic to search for.\n",
    "    Returns:\n",
    "        A JSON string containing a list of papers.\n",
    "    \"\"\"\n",
    "    print(f\"üîç Searching for: {query}...\")\n",
    "    papers = []\n",
    "    \n",
    "    # 1. ArXiv Search\n",
    "    try:\n",
    "        arxiv_client = arxiv.Client()\n",
    "        search = arxiv.Search(query=query, max_results=20, sort_by=arxiv.SortCriterion.Relevance)\n",
    "        for result in arxiv_client.results(search):\n",
    "            papers.append({\n",
    "                \"title\": result.title,\n",
    "                \"url\": result.entry_id,\n",
    "                \"abstract\": result.summary.replace(\"\\n\", \" \"),\n",
    "                \"authors\": \", \".join([a.name for a in result.authors]),\n",
    "                \"year\": result.published.year,\n",
    "                \"source\": \"ArXiv\"\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"ArXiv error: {e}\")\n",
    "\n",
    "    # 2. Web Search (DDGS)\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            keywords = f\"{query} research paper\"\n",
    "            results = list(ddgs.text(keywords, max_results=20))\n",
    "            for r in results:\n",
    "                papers.append({\n",
    "                    \"title\": r.get('title', 'No Title'),\n",
    "                    \"url\": r.get('href', ''),\n",
    "                    \"abstract\": r.get('body', ''),\n",
    "                    \"authors\": \"Unknown\",\n",
    "                    \"year\": \"Unknown\",\n",
    "                    \"source\": \"Web\"\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"Web search error: {e}\")\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(papers)} papers total\")\n",
    "    return json.dumps(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2cda73-861e-4bbd-ad3d-ef27eea20e80",
   "metadata": {},
   "source": [
    "## 4. Define Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2590c7a-19e4-468b-b108-7a69dd045b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:10:33.721764Z",
     "iopub.status.busy": "2025-11-30T12:10:33.721425Z",
     "iopub.status.idle": "2025-11-30T12:10:33.731630Z",
     "shell.execute_reply": "2025-11-30T12:10:33.730645Z",
     "shell.execute_reply.started": "2025-11-30T12:10:33.721715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Search Agent\n",
    "search_agent = LlmAgent(\n",
    "    name=\"SearchAgent\",\n",
    "    model=model,\n",
    "    instruction=\"\"\"\n",
    "    You are a Research Librarian.\n",
    "    Your goal is to find a broad list of research papers for a given query.\n",
    "    Use the `search_papers_tool` to get the raw data.\n",
    "    \n",
    "    Output: Return the raw JSON list of papers found.\n",
    "    \"\"\",\n",
    "    tools=[search_papers_tool],\n",
    "    description=\"Searches for research papers on ArXiv and Web\"\n",
    ")\n",
    "\n",
    "# 2. Selection Agent\n",
    "selection_agent = LlmAgent(\n",
    "    name=\"SelectionAgent\",\n",
    "    model=model,\n",
    "    instruction=\"\"\"\n",
    "    You are a Senior Editor.\n",
    "    Input: The list of research papers provided by the previous agent.\n",
    "    Task: Select the **top 5** most relevant and high-quality papers.\n",
    "    \n",
    "    Sorting Logic:\n",
    "    - Prioritize papers with a known Year.\n",
    "    - Sort the final 5 papers by Year (Descending/Newest First).\n",
    "    - The JSON array MUST be ordered such that index 0 is the newest paper.\n",
    "    \n",
    "    Output: Return the SORTED JSON list of 5 papers.\n",
    "    \"\"\",\n",
    "    description=\"Selects top 5 papers from search results\"\n",
    ")\n",
    "\n",
    "# 3. Extraction Agent\n",
    "extraction_agent = LlmAgent(\n",
    "    name=\"ExtractionAgent\",\n",
    "    model=model,\n",
    "    instruction=\"\"\"\n",
    "    You are a Research Analyst.\n",
    "    Input: The list of 5 selected papers provided by the previous agent.\n",
    "    Task: For each paper, extract:\n",
    "    - key_findings\n",
    "    - methodology\n",
    "    - relevance\n",
    "    \n",
    "    Output: Return the enriched JSON list with these details added.\n",
    "    \"\"\",\n",
    "    description=\"Extracts key findings from papers\"\n",
    ")\n",
    "\n",
    "# 4. Synthesis Agent (Iterative)\n",
    "synthesis_agent = LlmAgent(\n",
    "    name=\"SynthesisAgent\",\n",
    "    model=model,\n",
    "    instruction=\"\"\"\n",
    "    You are an Academic Writer.\n",
    "    Input: \n",
    "    - First run: A list of 5 analyzed papers.\n",
    "    - Subsequent runs: Your previous draft AND the Reviewer's feedback.\n",
    "    \n",
    "    Task: Write (or rewrite) a comprehensive literature review report.\n",
    "    \n",
    "    If you receive feedback, use it to IMPROVE your draft. Fix any issues mentioned.\n",
    "    \n",
    "    CRITICAL OUTPUT FORMAT:\n",
    "    - Write EXACTLY 5 paragraphs, one for each paper.\n",
    "    - **ORDER**: Discuss papers in the exact order provided (which is sorted by date).\n",
    "    - **PARAGRAPH START**: Start EACH paragraph with the first author's name and \"et al.\" (e.g., \"Pan et al. ...\").\n",
    "    - **CITATION**: End each paragraph with a sequential citation marker: [1], [2], [3], [4], [5].\n",
    "    \n",
    "    - **REFERENCES SECTION**:\n",
    "      Add a \"### References\" section at the end.\n",
    "      You MUST format this as a list.\n",
    "      CRITICAL: Put a BLANK LINE (double newline) between each reference.\n",
    "      \n",
    "      Example format:\n",
    "      [1] Title, Authors, Year, URL\n",
    "      \n",
    "      [2] Title, Authors, Year, URL\n",
    "      ...\n",
    "    \n",
    "    Output: Return the full literature review text.\n",
    "    \"\"\",\n",
    "    description=\"Writes literature review report\"\n",
    ")\n",
    "\n",
    "# 5. Evaluation Agent (Iterative)\n",
    "evaluation_agent = LlmAgent(\n",
    "    name=\"EvaluationAgent\",\n",
    "    model=model,\n",
    "    instruction=\"\"\"\n",
    "    You are a Reviewer.\n",
    "    Input: The literature review report provided by the previous agent.\n",
    "    Task: Evaluate if it follows the 5-paragraph format and has correct citations.\n",
    "    \n",
    "    OUTPUT:\n",
    "    - First, provide your Score (1-10) and brief feedback.\n",
    "    - Then, output the ORIGINAL literature review text exactly as received.\n",
    "    \n",
    "    If the score is low (< 8), be very specific about what needs to be fixed in your feedback.\n",
    "    \n",
    "    IMPORTANT: You are the final step of the loop. Return the full review text.\n",
    "    \"\"\",\n",
    "    description=\"Evaluates literature review quality\"\n",
    ")\n",
    "\n",
    "# Refinement Loop\n",
    "refinement_loop = LoopAgent(\n",
    "    name=\"RefinementLoop\",\n",
    "    description=\"Iteratively improves the literature review\",\n",
    "    sub_agents=[synthesis_agent, evaluation_agent],\n",
    "    max_iterations=2\n",
    ")\n",
    "\n",
    "# Main Workflow\n",
    "workflow = SequentialAgent(\n",
    "    name=\"LitReviewWorkflow\",\n",
    "    description=\"Full literature review workflow\",\n",
    "    sub_agents=[\n",
    "        search_agent,\n",
    "        selection_agent,\n",
    "        extraction_agent,\n",
    "        refinement_loop \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a163618b-a8ab-4955-9e04-019e75690f74",
   "metadata": {},
   "source": [
    "## 5. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f9d3676-c23a-468a-b478-3b08d4aa0fa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:32:46.780239Z",
     "iopub.status.busy": "2025-11-30T12:32:46.779880Z",
     "iopub.status.idle": "2025-11-30T12:32:46.787289Z",
     "shell.execute_reply": "2025-11-30T12:32:46.786496Z",
     "shell.execute_reply.started": "2025-11-30T12:32:46.780214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "async def run_literature_review(topic: str):\n",
    "    print(f\"üöÄ Starting Literature Review for: {topic}\")\n",
    "    \n",
    "    runner = InMemoryRunner(agent=workflow)\n",
    "    result = await runner.run_debug(topic,  quiet=True)\n",
    "    \n",
    "    # Extract final output\n",
    "    final_output = \"No output generated.\"\n",
    "    for event in reversed(result):\n",
    "        if hasattr(event, 'content') and event.content:\n",
    "            if hasattr(event.content, 'parts'):\n",
    "                for part in event.content.parts:\n",
    "                    if hasattr(part, 'text') and part.text:\n",
    "                        final_output = part.text.strip()\n",
    "                        break\n",
    "            if final_output != \"No output generated.\":\n",
    "                break\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL LITERATURE REVIEW\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    print(final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6c5b3-8788-4788-a759-96b452426d4e",
   "metadata": {},
   "source": [
    "**To Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64333dec-91df-4979-8be1-33b3499b7801",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:32:49.515346Z",
     "iopub.status.busy": "2025-11-30T12:32:49.515016Z",
     "iopub.status.idle": "2025-11-30T12:33:39.555064Z",
     "shell.execute_reply": "2025-11-30T12:33:39.553779Z",
     "shell.execute_reply.started": "2025-11-30T12:32:49.515322Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Literature Review for: write me a litereature review for the topic prediction and Analysis of Cardiovascular Disease Using Machine Learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/google/adk/runners.py:1268: DeprecationWarning: deprecated\n",
      "  save_input_blobs_as_artifacts=run_config.save_input_blobs_as_artifacts,\n",
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for: Prediction and Analysis of Cardiovascular Disease Using Machine Learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/3330948737.py:30: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 40 papers total\n",
      "\n",
      "============================================================\n",
      "FINAL LITERATURE REVIEW\n",
      "============================================================\n",
      "\n",
      "Score: 7/10\n",
      "\n",
      "Feedback: The literature review is well-structured and the content is relevant and informative. However, it still doesn't strictly adhere to the traditional 5-paragraph format (introduction, three body paragraphs, conclusion). While it has an introductory paragraph and a concluding thought within the last body paragraph, it lacks a distinct concluding paragraph summarizing the overall findings and implications. The citations are correct.\n",
      "\n",
      "```\n",
      "The application of machine learning (ML) has demonstrated substantial promise in enhancing the prediction and analysis of cardiovascular diseases (CVDs), which remain a leading cause of mortality globally. This review synthesizes recent research that employs various ML approaches for CVD risk assessment and prediction. The studies collectively highlight the potential of ML to identify intricate patterns and risk factors that are often missed by traditional methods, thereby improving diagnostic accuracy and facilitating more informed, proactive medical interventions. The reviewed literature covers direct prediction models for cardiovascular events, as well as foundational research on ML evaluation and privacy considerations crucial for healthcare applications.\n",
      "\n",
      "Pan et al. (2025) focused on predicting the risk of postoperative stroke in patients undergoing coronary revascularization, a critical complication in cardiovascular care. Their research employed a sophisticated machine learning pipeline, utilizing data from the MIMIC-IV database. Through meticulous data preprocessing, including handling missing values and multicollinearity, and the application of models like SVM, XGBoost, and CatBoost, they achieved a notable AUC of 0.855 with their SVM model. Crucially, their use of SHAP analysis identified key prognostic factors such as the Charlson Comorbidity Index (CCI), diabetes, chronic kidney disease, and heart failure. This work underscores that advanced ML, by integrating a wider range of clinically relevant characteristics, provides a more comprehensive and individualized risk assessment, thereby improving preoperative risk evaluation and targeted intervention strategies [1].\n",
      "\n",
      "In a related study directly addressing cardiovascular disease prediction, Miah et al. (2023) conducted a comparative analysis of six distinct machine learning models for predicting myocardial infarction. Their investigation highlighted the superior performance of tree-based ensemble methods, with XGBoost achieving an accuracy of 92.72% and LightGBM reaching 90.60%. These results significantly surpassed those of simpler models like Logistic Regression and Support Vector Machine. The findings emphasize that advanced ML techniques are potent tools for refining predictive precision in cardiovascular health and can substantially aid in developing more effective proactive medical interventions by accurately identifying critical risk factors such as smoking, elevated blood pressure, and cholesterol levels [4].\n",
      "\n",
      "Expanding the scope beyond direct CVD prediction, Dana et al. (2024) proposed an integrated approach that combines machine learning with survival analysis to enhance the risk stratification of chronic kidney disease (CKD). Recognizing the strong link between CKD and cardiovascular health, their study aimed to identify novel predictors of CKD progression using various ML models and Shapley values for feature importance. By integrating these new predictors with established clinical features from the Kidney Failure Risk Equation and applying Cox proportional hazards models, they aimed to improve early detection and management of CKD. Furthermore, Guerra-Manzanares et al. (2023) provided a crucial review of privacy-preserving machine learning (PPML) in healthcare, addressing the paramount importance of data privacy in ML pipelines dealing with sensitive medical information. Their work identifies current trends, challenges, and future directions for developing secure and efficient ML models in healthcare, which is fundamental for the responsible application of any predictive modeling in this domain [2, 3]. Finally, Mohr and van Rijn (2022) contributed foundational insights into the evaluation of machine learning models through their survey on learning curves. This research explains how learning curves, which track model performance against resources like training data or iterations, are essential for critical decision-making processes such as data acquisition, early stopping of model training, and model selection. By categorizing different learning curve approaches, their work provides a framework for understanding and optimizing the development of ML models. This is vital for ensuring that the models used for complex tasks like cardiovascular disease prediction are robust, efficient, and appropriately selected, ultimately contributing to reliable clinical decision support [5].\n",
      "\n",
      "In conclusion, the reviewed literature demonstrates the significant potential of machine learning in advancing the prediction and analysis of cardiovascular diseases. Studies have showcased the efficacy of sophisticated ML models like SVM, XGBoost, and LightGBM in accurately predicting cardiovascular events and identifying critical risk factors. Complementary research on CKD prediction, privacy-preserving ML, and model evaluation methodologies further solidifies the foundation for deploying these technologies responsibly and effectively in clinical settings. As ML continues to evolve, its role in improving cardiovascular healthcare through enhanced prediction, early detection, and personalized interventions is poised to grow substantially.\n",
      "\n",
      "### References\n",
      "\n",
      "[1] Machine Learning-Based Model for Postoperative Stroke Prediction in Coronary Artery Disease, Haonan Pan, Shuheng Chen, Elham Pishgar, Kamiar Alaei, Greg Placencia, Maryam Pishgar, 2025, http://arxiv.org/abs/2503.11973v1\n",
      "\n",
      "[2] Integrated Machine Learning and Survival Analysis Modeling for Enhanced Chronic Kidney Disease Risk Stratification, Zachary Dana, Ahmed Ammar Naseer, Botros Toro, Sumanth Swaminathan, 2024, http://arxiv.org/abs/2411.10754v1\n",
      "\n",
      "[3] Privacy-preserving machine learning for healthcare: open challenges and future perspectives, Alejandro Guerra-Manzanares, L. Julian Lechuga Lopez, Michail Maniatakos, Farah E. Shamout, 2023, http://arxiv.org/abs/2303.15563v1\n",
      "\n",
      "[4] Improving Cardiovascular Disease Prediction Through Comparative Analysis of Machine Learning Models: A Case Study on Myocardial Infarction, Jonayet Miah, Duc M Ca, Md Abu Sayed, Ehsanur Rashid Lipu, Fuad Mahmud, S M Yasir Arafat, 2023, http://arxiv.org/abs/2311.00517v1\n",
      "\n",
      "[5] Learning Curves for Decision Making in Supervised Machine Learning: A Survey, Felix Mohr, Jan N. van Rijn, 2022, http://arxiv.org/abs/2201.12150v2\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Run the review \n",
    "TOPIC = \"write me a litereature review for the topic prediction and Analysis of Cardiovascular Disease Using Machine Learning\"\n",
    "if GOOGLE_API_KEY:\n",
    "    await run_literature_review(TOPIC)\n",
    "else:\n",
    "    print(\"‚ùå Cannot run: API Key missing\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
