{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature Review Helper Agent\n",
    "\n",
    "This notebook implements a multi-agent system to conduct automated literature reviews.\n",
    "\n",
    "### Workflow:\n",
    "1.  **Search Agent**: Searches for papers using ArXiv API and Google Search (DuckDuckGo).\n",
    "2.  **Selection Agent**: Curates the top 5 most relevant papers from the search results.\n",
    "3.  **Extraction Agent**: Extracts key findings, methodologies, and conclusions from the selected papers.\n",
    "4.  **Synthesis Agent**: Writes a structured 5-paragraph literature review with citations.\n",
    "5.  **Evaluation Agent**: Critiques the quality of the generated review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install -q google-generativeai arxiv ddgs python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import arxiv\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from duckduckgo_search import DDGS\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    print(\"‚ùå Error: GOOGLE_API_KEY not found in .env file.\")\n",
    "else:\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    print(\"‚úÖ API Key loaded and Gemini configured.\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"gemini-1.5-flash\" # Or gemini-pro\n",
    "GENERATION_CONFIG = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Search Agent\n",
    "Combines ArXiv and Web Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchAgent:\n",
    "    def __init__(self):\n",
    "        self.arxiv_client = arxiv.Client()\n",
    "\n",
    "    def search_arxiv(self, query: str, max_results=20) -> List[Dict]:\n",
    "        print(f\"   Running ArXiv search for '{query}'...\")\n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            sort_by=arxiv.SortCriterion.Relevance\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        try:\n",
    "            for result in self.arxiv_client.results(search):\n",
    "                results.append({\n",
    "                    \"title\": result.title,\n",
    "                    \"url\": result.entry_id,\n",
    "                    \"abstract\": result.summary.replace(\"\\n\", \" \"),\n",
    "                    \"authors\": \", \".join([a.name for a in result.authors]),\n",
    "                    \"year\": result.published.year,\n",
    "                    \"source\": \"ArXiv\"\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è ArXiv search failed: {e}\")\n",
    "        return results\n",
    "\n",
    "    def search_web(self, query: str, max_results=20) -> List[Dict]:\n",
    "        print(f\"   Running Web search for '{query}'...\")\n",
    "        results = []\n",
    "        try:\n",
    "            with DDGS() as ddgs:\n",
    "                # Adding \"filetype:pdf\" or \"research paper\" to improve quality\n",
    "                keywords = f\"{query} research paper filetype:pdf\"\n",
    "                ddgs_results = list(ddgs.text(keywords, max_results=max_results))\n",
    "                \n",
    "                for r in ddgs_results:\n",
    "                    results.append({\n",
    "                        \"title\": r.get('title', 'No Title'),\n",
    "                        \"url\": r.get('href', ''),\n",
    "                        \"abstract\": r.get('body', ''),\n",
    "                        \"authors\": \"Unknown\", # Web search often misses authors in snippets\n",
    "                        \"year\": \"Unknown\",\n",
    "                        \"source\": \"Web\"\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Web search failed: {e}\")\n",
    "        return results\n",
    "\n",
    "    def search(self, query: str) -> List[Dict]:\n",
    "        print(f\"üîé [Search Agent] Starting search for: {query}\")\n",
    "        arxiv_results = self.search_arxiv(query)\n",
    "        web_results = self.search_web(query)\n",
    "        \n",
    "        combined = arxiv_results + web_results\n",
    "        print(f\"‚úÖ [Search Agent] Found {len(combined)} total papers (ArXiv: {len(arxiv_results)}, Web: {len(web_results)})\\n\")\n",
    "        return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selection Agent\n",
    "Selects the top 5 most relevant papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectionAgent:\n",
    "    def __init__(self, model_name=MODEL_NAME):\n",
    "        self.model = genai.GenerativeModel(model_name)\n",
    "\n",
    "    def select_best_papers(self, query: str, papers: List[Dict]) -> List[Dict]:\n",
    "        print(f\"üéØ [Selection Agent] Selecting top 5 papers from {len(papers)} candidates...\")\n",
    "        \n",
    "        # Prepare prompt\n",
    "        papers_str = \"\"\n",
    "        for i, p in enumerate(papers):\n",
    "            papers_str += f\"ID: {i}\\nTitle: {p['title']}\\nAbstract: {p['abstract'][:200]}...\\nSource: {p['source']}\\n\\n\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert research assistant. I have a list of papers related to the query: \"{query}\".\n",
    "        \n",
    "        Please select the **5 most relevant and high-quality papers** from the list below.\n",
    "        Return ONLY a JSON array of the 5 selected IDs. \n",
    "        Example: [0, 4, 7, 12, 15]\n",
    "\n",
    "        List of Papers:\n",
    "        {papers_str}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            text = response.text.strip()\n",
    "            \n",
    "            # Clean JSON\n",
    "            if \"```json\" in text:\n",
    "                text = text.split(\"```json\")[1].split(\"```\")[0]\n",
    "            elif \"```\" in text:\n",
    "                text = text.split(\"```\")[1].split(\"```\")[0]\n",
    "            \n",
    "            selected_ids = json.loads(text)\n",
    "            \n",
    "            selected_papers = []\n",
    "            for i in selected_ids:\n",
    "                if 0 <= i < len(papers):\n",
    "                    selected_papers.append(papers[i])\n",
    "            \n",
    "            # Fallback if model fails to return 5\n",
    "            if len(selected_papers) < 5:\n",
    "                print(\"   ‚ö†Ô∏è Model returned fewer than 5 papers, padding with top results.\")\n",
    "                for p in papers:\n",
    "                    if p not in selected_papers:\n",
    "                        selected_papers.append(p)\n",
    "                    if len(selected_papers) == 5:\n",
    "                        break\n",
    "            \n",
    "            selected_papers = selected_papers[:5]\n",
    "            print(f\"‚úÖ [Selection Agent] Selected {len(selected_papers)} papers.\")\n",
    "            return selected_papers\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå [Selection Agent] Error: {e}. Returning top 5 raw results.\")\n",
    "            return papers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extraction Agent\n",
    "Extracts details from the selected papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractionAgent:\n",
    "    def __init__(self, model_name=MODEL_NAME):\n",
    "        self.model = genai.GenerativeModel(model_name)\n",
    "\n",
    "    def extract_details(self, papers: List[Dict]) -> List[Dict]:\n",
    "        print(f\"‚õèÔ∏è [Extraction Agent] Extracting details from {len(papers)} papers...\")\n",
    "        extracted_data = []\n",
    "\n",
    "        for i, paper in enumerate(papers):\n",
    "            print(f\"   Processing {i+1}/5: {paper['title'][:50]}...\")\n",
    "            prompt = f\"\"\"\n",
    "            Analyze the following paper abstract and extract key details.\n",
    "            \n",
    "            Title: {paper['title']}\n",
    "            Abstract: {paper['abstract']}\n",
    "            \n",
    "            Return a JSON object with:\n",
    "            - \"key_findings\": (str) Main results or claims.\n",
    "            - \"methodology\": (str) How the research was conducted.\n",
    "            - \"relevance\": (str) Why this is important.\n",
    "            \"\"\"\n",
    "            \n",
    "            try:\n",
    "                response = self.model.generate_content(prompt)\n",
    "                text = response.text.strip()\n",
    "                if \"```json\" in text:\n",
    "                    text = text.split(\"```json\")[1].split(\"```\")[0]\n",
    "                elif \"```\" in text:\n",
    "                    text = text.split(\"```\")[1].split(\"```\")[0]\n",
    "                \n",
    "                data = json.loads(text)\n",
    "                \n",
    "                # Merge with original paper data\n",
    "                paper_data = paper.copy()\n",
    "                paper_data.update(data)\n",
    "                extracted_data.append(paper_data)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Extraction failed for paper {i}: {e}\")\n",
    "                paper_data = paper.copy()\n",
    "                paper_data.update({\"key_findings\": \"N/A\", \"methodology\": \"N/A\", \"relevance\": \"N/A\"})\n",
    "                extracted_data.append(paper_data)\n",
    "                \n",
    "        print(f\"‚úÖ [Extraction Agent] Finished extraction.\\n\")\n",
    "        return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Synthesis Agent\n",
    "Generates the 5-paragraph report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesisAgent:\n",
    "    def __init__(self, model_name=MODEL_NAME):\n",
    "        self.model = genai.GenerativeModel(model_name)\n",
    "\n",
    "    def synthesize_report(self, query: str, extracted_data: List[Dict]) -> str:\n",
    "        print(f\"‚úçÔ∏è [Synthesis Agent] Writing report for '{query}'...\")\n",
    "        \n",
    "        # Prepare data for prompt\n",
    "        data_str = json.dumps(extracted_data, indent=2)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are an academic writer. Write a literature review based on the following 5 papers.\n",
    "        \n",
    "        Research Query: \"{query}\"\n",
    "        \n",
    "        Papers Data:\n",
    "        {data_str}\n",
    "        \n",
    "        **Strict Output Format Requirements:**\n",
    "        1. Write exactly **5 paragraphs**. Each paragraph must focus on ONE paper in the order provided.\n",
    "        2. At the end of each paragraph, add the citation marker like [1], [2], [3], [4], [5].\n",
    "        3. After the 5 paragraphs, add a section titled \"### References\".\n",
    "        4. In the References section, list the full details for each paper (Title, Authors, Year, URL).\n",
    "        \n",
    "        Do not add any other intro or conclusion text. Just the 5 paragraphs and the references.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Synthesis failed: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation Agent\n",
    "Checks the quality of the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationAgent:\n",
    "    def __init__(self, model_name=MODEL_NAME):\n",
    "        self.model = genai.GenerativeModel(model_name)\n",
    "\n",
    "    def evaluate_report(self, report: str) -> str:\n",
    "        print(f\"‚öñÔ∏è [Evaluation Agent] Evaluating report quality...\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Evaluate the following literature review report.\n",
    "        \n",
    "        Report:\n",
    "        {report}\n",
    "        \n",
    "        Check for:\n",
    "        1. Are there exactly 5 paragraphs?\n",
    "        2. Are citations [1]-[5] used correctly?\n",
    "        3. Is the References section present and accurate?\n",
    "        \n",
    "        Provide a score (1-10) and brief feedback.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Evaluation failed: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinator & Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(query: str):\n",
    "    # Initialize Agents\n",
    "    search_agent = SearchAgent()\n",
    "    selection_agent = SelectionAgent()\n",
    "    extraction_agent = ExtractionAgent()\n",
    "    synthesis_agent = SynthesisAgent()\n",
    "    evaluation_agent = EvaluationAgent()\n",
    "    \n",
    "    print(f\"üöÄ Starting Literature Review for: '{query}'\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Search\n",
    "    raw_papers = search_agent.search(query)\n",
    "    if not raw_papers:\n",
    "        print(\"‚ùå No papers found. Exiting.\")\n",
    "        return\n",
    "        \n",
    "    # 2. Select\n",
    "    selected_papers = selection_agent.select_best_papers(query, raw_papers)\n",
    "    \n",
    "    # 3. Extract\n",
    "    extracted_data = extraction_agent.extract_details(selected_papers)\n",
    "    \n",
    "    # 4. Synthesize\n",
    "    report = synthesis_agent.synthesize_report(query, extracted_data)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìù FINAL LITERATURE REVIEW REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    print(report)\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # 5. Evaluate\n",
    "    evaluation = evaluation_agent.evaluate_report(report)\n",
    "    print(\"üìä Evaluation Results:\")\n",
    "    print(evaluation)\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the query here\n",
    "    query = \"Multi-Agent Systems in Large Language Models\"\n",
    "    main(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
