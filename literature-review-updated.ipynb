{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature Review Helper Agent (Google ADK Edition)\n",
    "\n",
    "This notebook implements a multi-agent system using **Google's Agent Development Kit (ADK)**.\n",
    "\n",
    "### Workflow:\n",
    "1.  **Search Agent**: Uses tools to find papers (ArXiv + Google).\n",
    "2.  **Selection Agent**: Curates the top 5 papers.\n",
    "3.  **Extraction Agent**: Extracts details.\n",
    "4.  **Synthesis Agent**: Writes the report.\n",
    "5.  **Evaluation Agent**: Critiques the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T08:43:53.218532Z",
     "iopub.status.busy": "2025-11-29T08:43:53.218217Z",
     "iopub.status.idle": "2025-11-29T08:43:58.088085Z",
     "shell.execute_reply": "2025-11-29T08:43:58.086797Z",
     "shell.execute_reply.started": "2025-11-29T08:43:53.218506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install -q google-generativeai arxiv duckduckgo-search ddgs python-dotenv google-adk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T08:44:04.610572Z",
     "iopub.status.busy": "2025-11-29T08:44:04.610231Z",
     "iopub.status.idle": "2025-11-29T08:44:04.843500Z",
     "shell.execute_reply": "2025-11-29T08:44:04.842498Z",
     "shell.execute_reply.started": "2025-11-29T08:44:04.610540Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# Setup Gemini API\n",
    "try:\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "    print(\"âœ… API key configured\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T09:34:39.656830Z",
     "iopub.status.busy": "2025-11-29T09:34:39.656529Z",
     "iopub.status.idle": "2025-11-29T09:34:39.663808Z",
     "shell.execute_reply": "2025-11-29T09:34:39.662920Z",
     "shell.execute_reply.started": "2025-11-29T09:34:39.656811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import arxiv\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from duckduckgo_search import DDGS\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "# Google ADK Imports\n",
    "from google.adk.agents import Agent, SequentialAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.genai import types\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools import google_search, AgentTool, ToolContext\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "model = Gemini(model_name=MODEL_NAME, api_key=GOOGLE_API_KEY)\n",
    "GENERATION_CONFIG = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T09:34:43.822910Z",
     "iopub.status.busy": "2025-11-29T09:34:43.822537Z",
     "iopub.status.idle": "2025-11-29T09:34:43.827651Z",
     "shell.execute_reply": "2025-11-29T09:34:43.826699Z",
     "shell.execute_reply.started": "2025-11-29T09:34:43.822884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configure Retry Options\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Tools\n",
    "We define the search capabilities as tools that agents can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T09:34:46.934994Z",
     "iopub.status.busy": "2025-11-29T09:34:46.934661Z",
     "iopub.status.idle": "2025-11-29T09:34:46.943802Z",
     "shell.execute_reply": "2025-11-29T09:34:46.942826Z",
     "shell.execute_reply.started": "2025-11-29T09:34:46.934973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def search_papers_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches for research papers on ArXiv and Web.\n",
    "    Args:\n",
    "        query: The research topic to search for.\n",
    "    Returns:\n",
    "        A JSON string containing a list of papers.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ› ï¸ [Tool] Running Search for: {query}\")\n",
    "    papers = []\n",
    "    \n",
    "    # 1. ArXiv Search\n",
    "    try:\n",
    "        arxiv_client = arxiv.Client()\n",
    "        search = arxiv.Search(query=query, max_results=20, sort_by=arxiv.SortCriterion.Relevance)\n",
    "        for result in arxiv_client.results(search):\n",
    "            papers.append({\n",
    "                \"title\": result.title,\n",
    "                \"url\": result.entry_id,\n",
    "                \"abstract\": result.summary.replace(\"\\n\", \" \"),\n",
    "                \"authors\": \", \".join([a.name for a in result.authors]),\n",
    "                \"year\": result.published.year,\n",
    "                \"source\": \"ArXiv\"\n",
    "            })\n",
    "        print(f\"   âœ… Found {len(papers)} ArXiv papers\")  \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ ArXiv error: {e}\")\n",
    "\n",
    "    # 2. Web Search (DDGS)\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            keywords = f\"{query} research paper\"\n",
    "            results = list(ddgs.text(keywords, max_results=20))\n",
    "            for r in results:\n",
    "                papers.append({\n",
    "                    \"title\": r.get('title', 'No Title'),\n",
    "                    \"url\": r.get('href', ''),\n",
    "                    \"abstract\": r.get('body', ''),\n",
    "                    \"authors\": \"Unknown\",\n",
    "                    \"year\": \"Unknown\",\n",
    "                    \"source\": \"Web\"\n",
    "                })\n",
    "        print(f\"   âœ… Found {len(results)} web results\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ Web search error: {e}\")\n",
    "    print(f\"   ðŸ“Š Total papers found: {len(papers)}\\n\")\n",
    "    return json.dumps(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define ADK Agents\n",
    "We create specialized agents using the `LlmAgent` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T09:35:18.688708Z",
     "iopub.status.busy": "2025-11-29T09:35:18.688343Z",
     "iopub.status.idle": "2025-11-29T09:35:18.695834Z",
     "shell.execute_reply": "2025-11-29T09:35:18.694406Z",
     "shell.execute_reply.started": "2025-11-29T09:35:18.688683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config)\n",
    "# 1. Search Agent\n",
    "search_agent = LlmAgent(\n",
    "    name=\"SearchAgent\",\n",
    "    model=model,\n",
    "    instruction=\"\"\"\n",
    "    You are a Research Librarian.\n",
    "    Your goal is to find a broad list of research papers for a given query.\n",
    "    Use the `search_papers_tool` to get the raw data.\n",
    "    Return the raw JSON list of papers found.\n",
    "    \"\"\",\n",
    "    tools=[search_papers_tool],\n",
    "    description=\"Searches for research papers on ArXiv and Web\"\n",
    ")\n",
    "\n",
    "# 2. Selection Agent\n",
    "selection_agent = LlmAgent(\n",
    "    name=\"SelectionAgent\",\n",
    "    model=model,\n",
    "    instruction=\"\"\"\n",
    "    You are a Senior Editor.\n",
    "    Input: A JSON list of research papers.\n",
    "    Task: Select the **top 5** most relevant and high-quality papers.\n",
    "    \n",
    "    Sorting Logic:\n",
    "    - Prioritize papers with a known Year.\n",
    "    - Sort the final 5 papers by Year (Descending/Newest First).\n",
    "    \n",
    "    Output: Return ONLY a JSON array of the 5 selected paper objects.\n",
    "    \"\"\",\n",
    "    description=\"Selects top 5 papers from search results\"\n",
    ")\n",
    "\n",
    "# 3. Extraction Agent\n",
    "extraction_agent = LlmAgent(\n",
    "    name=\"ExtractionAgent\",\n",
    "    model=model,\n",
    "    instruction=\"\"\"\n",
    "    You are a Research Analyst.\n",
    "    Input: A JSON list of 5 papers.\n",
    "    Task: For each paper, extract:\n",
    "    - key_findings\n",
    "    - methodology\n",
    "    - relevance\n",
    "    \n",
    "    Output: Return the same JSON list but with these new fields added to each paper object.\n",
    "    \"\"\",\n",
    "    description=\"Extracts key findings from papers\"\n",
    ")\n",
    "\n",
    "# 4. Synthesis Agent\n",
    "synthesis_agent = LlmAgent(\n",
    "    name=\"SynthesisAgent\",\n",
    "    model=model,\n",
    "    instruction=\"\"\"\n",
    "    You are an Academic Writer.\n",
    "    Input: A JSON list of 5 analyzed papers.\n",
    "    Task: Write a literature review report.\n",
    "    \n",
    "    Strict Format:\n",
    "    1. Exactly 5 paragraphs (one per paper).\n",
    "    2. End each paragraph with a citation marker [1], [2], etc.\n",
    "    3. Add a '### References' section at the end with full details.\n",
    "    \n",
    "    Do not add any other intro or conclusion text. Just the report.\n",
    "    \"\"\",\n",
    "    description=\"Writes literature review report\"\n",
    ")\n",
    "\n",
    "# 5. Evaluation Agent\n",
    "evaluation_agent = LlmAgent(\n",
    "    name=\"EvaluationAgent\",\n",
    "    model=model,\n",
    "    instruction=\"\"\"\n",
    "    You are a Reviewer.\n",
    "    Input: A literature review report.\n",
    "    Task: Evaluate if it follows the 5-paragraph format and has correct citations.\n",
    "    Output: A score (1-10) and brief feedback.\n",
    "    \"\"\",\n",
    "    description=\"Evaluates literature review quality\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Coordinator Agent\n",
    "We create a coordinator agent that manages all sub-agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T09:35:22.530890Z",
     "iopub.status.busy": "2025-11-29T09:35:22.530486Z",
     "iopub.status.idle": "2025-11-29T09:35:22.536793Z",
     "shell.execute_reply": "2025-11-29T09:35:22.535895Z",
     "shell.execute_reply.started": "2025-11-29T09:35:22.530864Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All agents initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Coordinator Agent\n",
    "coordinator = LlmAgent(\n",
    "    name=\"LiteratureReviewCoordinator\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Coordinates the literature review process\",\n",
    "    instruction=\"\"\"\n",
    "    You are a Research Coordinator.\n",
    "    Your task is to coordinate a multi-agent literature review process.\n",
    "    \n",
    "    Workflow:\n",
    "    1. Use SearchAgent to find papers\n",
    "    2. Use SelectionAgent to select top 5 papers\n",
    "    3. Use ExtractionAgent to extract key details\n",
    "    4. Use SynthesisAgent to write the review\n",
    "    5. Use EvaluationAgent to evaluate the review\n",
    "    \n",
    "    Return the final evaluated report.\n",
    "    \"\"\",\n",
    "    sub_agents=[\n",
    "        search_agent,\n",
    "        selection_agent,\n",
    "        extraction_agent,\n",
    "        synthesis_agent,\n",
    "        evaluation_agent\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"âœ… All agents initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To run interactively, save this file and use:\n",
    "# adk run\n",
    "# or\n",
    "# adk web\n",
    "\n",
    "# For programmatic access:\n",
    "query = \"Multi-Agent Systems in Large Language Models\"\n",
    "print(f\"ðŸš€ Literature Review Query: {query}\")\n",
    "print(\"\\nâ„¹ï¸ To run this agent, use: adk run\")\n",
    "print(\"   Or for web UI: adk web\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T09:40:39.107088Z",
     "iopub.status.busy": "2025-11-29T09:40:39.106752Z",
     "iopub.status.idle": "2025-11-29T09:40:39.113173Z",
     "shell.execute_reply": "2025-11-29T09:40:39.112243Z",
     "shell.execute_reply.started": "2025-11-29T09:40:39.107067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Runner created.\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=coordinator)\n",
    "\n",
    "print(\"âœ… Runner created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T09:43:02.595204Z",
     "iopub.status.busy": "2025-11-29T09:43:02.594898Z",
     "iopub.status.idle": "2025-11-29T09:43:08.778288Z",
     "shell.execute_reply": "2025-11-29T09:43:08.777307Z",
     "shell.execute_reply.started": "2025-11-29T09:43:02.595185Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Continue session: debug_session_id\n",
      "\n",
      "User > Prediction and Analysis of Cardiovascular Disease Using Machine Learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ› ï¸ [Tool] Running Search for: weather in London\n",
      "   âœ… Found 20 ArXiv papers\n",
      "   âœ… Found 0 web results\n",
      "   ðŸ“Š Total papers found: 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/545376598.py:31: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchAgent > I cannot provide real-time weather information. However, I can search for research papers related to weather forecasting. I found the following papers that might be relevant:\n",
      "\n",
      "*   **Verification of Space Weather Forecasts issued by the Met Office Space Weather Operations Centre**\n",
      "*   **Flare forecasting at the Met Office Space Weather Operations Centre**\n",
      "*   **The importance of ensemble techniques for operational space weather forecasting**\n",
      "*   **International Coordination and Support for SmallSat-enabled Space Weather Activities**\n",
      "*   **Addressing Gaps in Space Weather Observations that can be addressed with small satellites**\n",
      "*   **Small Satellite Mission Concepts for Space Weather Research and as Pathfinders for Operations**\n",
      "*   **A CNN-RNN Architecture for Multi-Label Weather Recognition**\n",
      "*   **Achievements and Lessons Learned from Successful Small Satellite Missions for Space Weather-Oriented Research**\n",
      "*   **Personalized real time weather forecasting**\n",
      "*   **Climate, weather, space weather: model development in an operational context**\n",
      "*   **Pangu-Weather: A 3D High-Resolution Model for Fast and Accurate Global Weather Forecast**\n",
      "*   **Socio-economic hazards and impacts of space weather: the important range between mild and extreme**\n",
      "*   **Summary of the plenary sessions at European Space Weather Week 15: space weather users and service providers working together now and in the future**\n",
      "*   **French on London and Bauer, and QBism**\n",
      "*   **Foundation Models for Weather and Climate Data Understanding: A Comprehensive Survey**\n",
      "*   **SPARX: a modelling system for Solar Energetic Particle Radiation Space Weather forecasting**\n",
      "*   **Verification of the NOAA Space Weather Prediction Center solar flare forecast (1998-2024)**\n",
      "*   **OSPREI: A Coupled Approach to Modeling CME-Driven Space Weather with Automatically-Generated, User-Friendly Outputs**\n",
      "*   **Machine learning for weather and climate are worlds apart**\n",
      "*   **Efficient Localized Adaptation of Neural Weather Forecasting: A Case Study in the MENA Region**\n"
     ]
    }
   ],
   "source": [
    "response = await runner.run_debug(\"Prediction and Analysis of Cardiovascular Disease Using Machine Learning\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
